{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/bk/8pjj70sj10z2sj7tfv3bzhq40000gn/T/ipykernel_10609/1881599250.py:17: MatplotlibDeprecationWarning: The seaborn styles shipped by Matplotlib are deprecated since 3.6, as they no longer correspond to the styles shipped by seaborn. However, they will remain available as 'seaborn-v0_8-<style>'. Alternatively, directly use the seaborn API instead.\n",
      "  plt.style.use(\"seaborn\")\n",
      "2023-08-26 18:49:00.081545: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M2 Pro\n",
      "2023-08-26 18:49:00.081562: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 16.00 GB\n",
      "2023-08-26 18:49:00.081567: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 5.33 GB\n",
      "2023-08-26 18:49:00.081598: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:303] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-08-26 18:49:00.081613: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:269] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "import ssl\n",
    "\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import cv2\n",
    "import math\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from collections import deque\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use(\"seaborn\")\n",
    "\n",
    "device = torch.device('mps:0' if torch.backends.mps.is_available() else 'cpu')\n",
    " \n",
    "from sklearn.model_selection import train_test_split\n",
    " \n",
    "from keras.layers import *\n",
    "from keras.models import Sequential\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.utils import plot_model\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from IPython.display import HTML\n",
    "from base64 import b64encode\n",
    "\n",
    "from keras.models import load_model\n",
    "MoBiLSTM_model = load_model('MoBiLSTM_model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MoBiLSTM_model = load_model('MoBiLSTM_model.h5')\n",
    "\n",
    "# Specify the height and width to which each video frame will be resized in our dataset.\n",
    "IMAGE_HEIGHT , IMAGE_WIDTH = 64, 64\n",
    " \n",
    "# Specify the number of frames of a video that will be fed to the model as one sequence.\n",
    "SEQUENCE_LENGTH = 16\n",
    "\n",
    "DATASET_DIR = \"dataset/archive/Real Life Violence Dataset\"\n",
    "\n",
    "CLASSES_LIST = [\"NonViolence\",\"Violence\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'dataset/archive/Real Life Violence Dataset/NonViolence'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mdataset_learning\u001b[39;00m \u001b[39mimport\u001b[39;00m Play_Video\n\u001b[1;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mdataset_learning\u001b[39;00m \u001b[39mimport\u001b[39;00m frames_extraction\n\u001b[1;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mdataset_learning\u001b[39;00m \u001b[39mimport\u001b[39;00m create_dataset\n",
      "File \u001b[0;32m~/Desktop/personal/school/IJSHS/2023/''' 2023 입시/CSB/특기 입증자료/OpenCV를 이용한 CCTV 분석 스마트 보안 시스템/dataset/archive/dataset_learning.py:47\u001b[0m\n\u001b[1;32m     44\u001b[0m ViolnceVideos_Dir \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mdataset/archive/Real Life Violence Dataset/Violence\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     46\u001b[0m \u001b[39m# Retrieve the list of all the video files present in the Class Directory.\u001b[39;00m\n\u001b[0;32m---> 47\u001b[0m NonViolence_files_names_list \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39;49mlistdir(NonViolnceVideos_Dir)\n\u001b[1;32m     48\u001b[0m Violence_files_names_list \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mlistdir(ViolnceVideos_Dir)\n\u001b[1;32m     50\u001b[0m \u001b[39m# Randomly select a video file from the Classes Directory.\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'dataset/archive/Real Life Violence Dataset/NonViolence'"
     ]
    }
   ],
   "source": [
    "from dataset_learning import Play_Video\n",
    "from dataset_learning import frames_extraction\n",
    "from dataset_learning import create_dataset\n",
    "from dataset_learning import predict_frames\n",
    "from dataset_learning import show_pred_frames\n",
    "from dataset_learning import predict_video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
